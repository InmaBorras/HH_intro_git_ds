{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ajuste del Modelo de Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from scipy import stats\n",
    "\n",
    "# Configuración matplotlib\n",
    "# ==============================================================================\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "#plt.rcParams['figure.dpi'] = \"100\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar separamos los datos de training de los datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que separa el juego de datos entre datos de entrenamiento y datos de trainning\n",
    "def split_model (Dataset_features,Dataset_target):\n",
    "# realizamos la división entre test y trainning\n",
    "    df_feat_train,df_feat_test,df_targ_train,df_targ_test = train_test_split(\n",
    "                                        Dataset_features,\n",
    "                                        Dataset_target.values.reshape(-1,1),\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 1234,\n",
    "                                        shuffle      = True\n",
    "                                    )\n",
    "    return df_feat_train,df_feat_test,df_targ_train,df_targ_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo de manera manual\n",
    "# Param in : \n",
    "# df_features --> dataframe con la features para entrenae el modelo\n",
    "def create_manual_model (df_features_tr,df_target_tr):\n",
    "    df_in_model=pd.DataFrame(\n",
    "                     np.hstack((df_features_tr, df_target_tr)),\n",
    "                     columns=['Distance_NEW', 'Rooms', 'Bathroom', 'Price']\n",
    "               )\n",
    "    modelo = smf.ols(formula = 'Price ~ Distance_NEW + Rooms + Bathroom', data = df_in_model)\n",
    "    modelo = modelo.fit()\n",
    "    print(modelo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo utilizando matrices como en scikitlearn\n",
    "# A la matriz de predictores se le tiene que añadir una columna de 1s para el intercept del modelo\n",
    "def create_model_scikitlearn(df_features_tr,df_target_tr):\n",
    "    df_features = sm.add_constant(df_features_tr, prepend=True)\n",
    "    modelo = sm.OLS(endog=df_target_tr, exog=df_features_tr,)\n",
    "    modelo = modelo.fit()\n",
    "    print(modelo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para calcular los intervalos de confianza\n",
    "def calcular_intervalos_de_Confianza(modelo,al):\n",
    "    intervalos_ci = modelo.conf_int(alpha=0.05)\n",
    "    intervalos_ci.columns = ['2.5%', '97.5%']\n",
    "    print (intervalos_ci)\n",
    "    return intervalos_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_residuos(df_features_tr,df_target_tr):\n",
    "    df_target = y_train.flatten()\n",
    "    prediccion_train = modelo.predict(exog = df_features_tr)\n",
    "    residuos_train   = prediccion_train - df_target_tr\n",
    "    print(\"Residuos\",residuos_train)\n",
    "    return residuos_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspeccion_visual_modelo(df_target_tr,prediccion_train,residuos_train):\n",
    "    # Gráficos\n",
    "    # ==============================================================================\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(9, 8))\n",
    "\n",
    "    axes[0, 0].scatter(df_target_tr, prediccion_train, edgecolors=(0, 0, 0), alpha = 0.4)\n",
    "    axes[0, 0].plot([df_target_tr.min(), df_target_tr.max()], [y_trdf_target_train.min(), df_target_tr.max()],\n",
    "                'k--', color = 'black', lw=2)\n",
    "    axes[0, 0].set_title('Valor predicho vs valor real', fontsize = 10, fontweight = \"bold\")\n",
    "    axes[0, 0].set_xlabel('Real')\n",
    "    axes[0, 0].set_ylabel('Predicción')\n",
    "    axes[0, 0].tick_params(labelsize = 7)\n",
    "\n",
    "    axes[0, 1].scatter(list(range(len(df_target_tr))), residuos_train,\n",
    "                   edgecolors=(0, 0, 0), alpha = 0.4)\n",
    "    axes[0, 1].axhline(y = 0, linestyle = '--', color = 'black', lw=2)\n",
    "    axes[0, 1].set_title('Residuos del modelo', fontsize = 10, fontweight = \"bold\")\n",
    "    axes[0, 1].set_xlabel('id')\n",
    "    axes[0, 1].set_ylabel('Residuo')\n",
    "    axes[0, 1].tick_params(labelsize = 7)\n",
    "\n",
    "    sns.histplot(\n",
    "    data    = residuos_train,\n",
    "    stat    = \"density\",\n",
    "    kde     = True,\n",
    "    line_kws= {'linewidth': 1},\n",
    "    color   = \"firebrick\",\n",
    "    alpha   = 0.3,\n",
    "    ax      = axes[1, 0]\n",
    "    )\n",
    "\n",
    "    axes[1, 0].set_title('Distribución residuos del modelo', fontsize = 10,\n",
    "                     fontweight = \"bold\")\n",
    "    axes[1, 0].set_xlabel(\"Residuo\")\n",
    "    axes[1, 0].tick_params(labelsize = 7)\n",
    "\n",
    "\n",
    "    sm.qqplot(\n",
    "    residuos_train,\n",
    "    fit   = True,\n",
    "    line  = 'q',\n",
    "    ax    = axes[1, 1], \n",
    "    color = 'firebrick',\n",
    "    alpha = 0.4,\n",
    "    lw    = 2\n",
    "    )\n",
    "    axes[1, 1].set_title('Q-Q residuos del modelo', fontsize = 10, fontweight = \"bold\")\n",
    "    axes[1, 1].tick_params(labelsize = 7)\n",
    "\n",
    "    axes[2, 0].scatter(prediccion_train, residuos_train,\n",
    "                   edgecolors=(0, 0, 0), alpha = 0.4)\n",
    "    axes[2, 0].axhline(y = 0, linestyle = '--', color = 'black', lw=2)\n",
    "    axes[2, 0].set_title('Residuos del modelo vs predicción', fontsize = 10, fontweight = \"bold\")\n",
    "    axes[2, 0].set_xlabel('Predicción')\n",
    "    axes[2, 0].set_ylabel('Residuo')\n",
    "    axes[2, 0].tick_params(labelsize = 7)\n",
    "\n",
    "    # Se eliminan los axes vacíos\n",
    "    fig.delaxes(axes[2,1])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    fig.suptitle('Diagnóstico residuos', fontsize = 12, fontweight = \"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normalidad_shapiro (residuos_train):\n",
    "    shapiro_test = stats.shapiro(residuos_train)\n",
    "    print (shapiro_test)\n",
    "    return shapiro_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normalidad_Dagostino():\n",
    "    k2, p_value = stats.normaltest(residuos_train)\n",
    "    print(f\"Estadítico= {k2}, p-value = {p_value}\")\n",
    "    return k2,p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir(modelo,intervalo_confianza):\n",
    "    predicciones = modelo.get_prediction(exog = X_train).summary_frame(alpha=intervalo_confianza)\n",
    "    print(predicciones.head(4))\n",
    "    return predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_error_RMSE(df_features_test,df_target_test):\n",
    "# Error de test del modelo \n",
    "# ==============================================================================\n",
    "    X_test = sm.add_constant(df_features_test, prepend=True)\n",
    "    predicciones = modelo.predict(exog = df_features_test)\n",
    "    rmse = mean_squared_error(\n",
    "        y_true  = df_target_test,\n",
    "        y_pred  = predicciones,\n",
    "        squared = False\n",
    "       )\n",
    "    print(\"\")\n",
    "    print(f\"El error (rmse) de test es: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparar_modelos_anova(model1,model2):\n",
    "   anova_lm(modelo, modelo_interacion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```{toctree}\n",
    ":hidden:\n",
    ":titlesonly:\n",
    "\n",
    "\n",
    "markdown\n",
    "notebooks\n",
    "notebooks\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
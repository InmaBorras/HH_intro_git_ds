{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Limpieza de los datos\n",
    "\n",
    "Tras es análisis de la variables hemos detectado tanto duplicidades en los datos como presencia de datos faltantes. Procedemos a la limpieza de los datos para la posterior construcción de un modelo mas exacto. \n",
    "\n",
    "### 5.1 Eliminacion de duplicados\n",
    "\n",
    "En el análisis de las variables cualitativas obsevamos que algunos datos tenian la misma dirección y precio.\n",
    "Basandonos en este razonamiento, realizamos una funcion que  elimine las filas que tengan las variables 'Address','SellerG','Price' y 'Date'   iguales. \n",
    "\n",
    "\n",
    "Numero de duplicados que hay??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from plotnine import ggplot, aes, geom_line, geom_point, geom_bar, geom_boxplot\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import missingno as msno\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pwlf\n",
    "import fundamentos_datos.py\n",
    "data= pd.read_csv('/home/inma/HH_intro_git_ds/Melbourne_housing_FULL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_duplicados(dataframe_bueno):\n",
    "    import pdb;pdb.set_trace()\n",
    "    duplicateRowsDF=pd.DataFrame()\n",
    "    duplicateRowsDF = dataframe_bueno[dataframe_bueno.duplicated(['Suburb', 'Address','Postcode','CouncilArea',],keep=False)]\n",
    "    duplicateRowsDF=duplicateRowsDF.drop_duplicates(subset=['Address','SellerG','Price','Date'])\n",
    "    duplicateRowsDF=duplicateRowsDF.dropna(subset=['Price'])\n",
    "    dataframe_bueno=dataframe_bueno.drop_duplicates(subset=['Address','Suburb'], keep=False, ignore_index=True)# por que lo haces de nuevo??\n",
    "    dataframe_bueno=pd.concat([dataframe_bueno, duplicateRowsDF], axis=1,join='inner')\n",
    "    dataframe_bueno=dataframe_bueno.dropna(subset=['Price'])\n",
    "    dataframe_bueno=dataframe_bueno.reset_index(drop=True)\n",
    "    return(dataframe_bueno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cogermos tdos los que tienenla misma direccion y se carga los que tienen el mis precio y el mismo dia. \n",
    " despues quitan todos loq eu tiene precio nulo. \n",
    " \n",
    " despues todos los duplicados por direcci\n",
    " \n",
    " hace drop de todos los duplicados del data drma bueos  e incluye los que iteresante y quita  los del precio. \n",
    "  len y comentar un poc hehco. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_duplicados=eliminar_duplicados(data)\n",
    "#data_duplicados.head()\n",
    "print(len(data_duplicados))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Detección e Imputación de Datos Faltantes\n",
    "\n",
    "Una vez eliminiados los datos duplicados, para finalizar la preparación de los datos es necesario eliminar los datos faltantes. \n",
    "\n",
    "Para ellos en primer lugar representamos gráficamente los datos faltantes en cada una de las variables realizando  una función de visualización. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primero quitamos los  de abajo como queutamos \n",
    "\n",
    " crear lista de missig y metemos todas ls comlumnsa que sitnen mas de 1000 perdidas  y el reso lo mete en lista de parametros. que es para avriguar la informacion \n",
    " \n",
    " se recorere la lsia de mssing entera e ir reyenandola lian 385  coe todas al filas que tiene missing de esa una columna donde el data frame  mete todos los nulos. \n",
    " \n",
    "  crea df filter donde mete  todas las filas qqde al columan que es difenete de nulo. \n",
    "  \n",
    "  tiene nulso y no nulos en dos data gra \n",
    " \n",
    " hace predicciond e variables con todos lso tdata frmaes anteriores. \n",
    " \n",
    " df missing donde todos los varoles e la coulua price es 0 \n",
    " df filter tiene todos los que stna bien \n",
    "  lista de parametros = features \n",
    "  \n",
    "  entonces usa Kfold- simplemente  que divide el data rame en 5 partes  paa separlo por el test. obtiene undata fram test y uno data fram training  despues se crea u una x de entramiento y yna y de entramiento donde  x es unaa fram con todas ls caractisticas con lalista de parametros. \n",
    "  \n",
    "  creamos un modelo de regresion lineanl en la cual entremos el y tran y el x train y predecimos los valroes  y cremaos una lista que se llama y price lineal. \n",
    "  \n",
    "   hacmeos lo msimo con radm forest   metemos en una lista la predicion del modelo  que se llama rf de randon forest. \n",
    "   \n",
    "   \n",
    "   \n",
    " como kold tiene  tamano 5 pes entonces recorre el modelo y hace 5 predciiones difrentes en funcion de losd atos y como queremos obtener  el mejor \n",
    "  haceos una funcio lamadao error cuadratico apara ver si es mejor la reglerios o el radom fores \n",
    "   y la funcion coger el error cuadratico de la lsita \n",
    "   \n",
    "    y por ultimo lo divide entre 5  hace la media de lso errores y con eso  se comprar el error cuadratico de loneal y el del random fores \n",
    "    \n",
    "  hace la condicin de si uno es mejor que el otro: \n",
    "     \n",
    " el de lineal es  mayor po loq ue del random fores est mejor \n",
    " y usamos eso. para entrenar el modelo  usamos todos el dataframe  y como quermos predecir los misiinf de  x test _ missing  \n",
    "      \n",
    "       entonces al crear l modello y entrealo con lso datos de data filter hacemos una prediccion de estos vamores de  rooms distance post ode y proportey count y se queda con ellos y mete esos datos en el data frame \n",
    "       \n",
    "dependideno de la variables se usa una u otros  de lso modelos regresion linan o random forest. \n",
    "\n",
    "\n",
    " y yacomo las variable no tienen ningun missing metemeos las variabels dentrode lista de paramentros y incorporan a al de la siguente variable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizacion_missings(dataframe):\n",
    "    #ELIMINACION VISUALIZACION Y SUSTITUCION DE LOS MISSINGS\n",
    "    print(dataframe.isnull().sum())\n",
    "    msno.matrix(dataframe)\n",
    "    plt.show()\n",
    "    msno.heatmap(dataframe)\n",
    "    plt.show()\n",
    "    # Missingno library also provides heatmaps that show if there is any correlation between missing values in different columns.\n",
    "    msno.bar(dataframe)\n",
    "    plt.show()\n",
    "'''import pdb;pdb.set_trace()\n",
    "lista_true=[[5,7,9,11,13],[2,4,6,8,10]]\n",
    "lista_pred=[[19/4,40/6,8,12,13],[5/2,7/2,13/2,17/2,9]]\n",
    "ec_prueba=error_cuadratico(lista_true,lista_pred)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizacion_missings(data_duplicados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se detecta que hay variables donde no existen datos faltantes mientras que en otras el número es muy alto. En este punto es importante seleccionar de forma adecuada la imputación de los mismo. \n",
    "\n",
    "Directamente descargamos las variables \"YearBuilt\", \"BuildingArea\" y \"Bedroom2\" ya que presentan muchos datos faltantes además de una baja correlación y/o muchas similitud con otras variables como en el caso de \"Bedrooms2\" y \"rooms\". \n",
    "\n",
    " De lo otro no me acuerdo qe has hecho ni lo entiendo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('/home/inma/HH_intro_git_ds/precios_casas_full.csv')\n",
    "dataframe_bueno=pd.DataFrame()\n",
    "#dataframe=dataframe[dataframe.BuildingArea.drop()]\n",
    "dataframe_final=pd.DataFrame()\n",
    "import pdb;pdb.set_trace()\n",
    "#dataframe=dataframe.dropna(subset=['Price'])\n",
    "for i in dataframe.keys():\n",
    "    if(i!='YearBuilt' and i!='BuildingArea' and i!='Bedroom2'):\n",
    "        dataframe_final[i]=dataframe[i]\n",
    "dataframe=dataframe_final\n",
    "lista_parametros=list()\n",
    "lista_missings=list()\n",
    "for index, i in enumerate(dataframe.keys()):\n",
    "    if(isinstance(dataframe.iloc[0][index], ( np.int64))  or isinstance(dataframe.iloc[0][index],(np.float64)) ):\n",
    "        if(dataframe[str(i)].isna().sum()>1000):\n",
    "            lista_missings.append(i)\n",
    "        else:\n",
    "            lista_parametros.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_bueno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
